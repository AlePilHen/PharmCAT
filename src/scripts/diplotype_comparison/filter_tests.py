#!/usr/bin/env python3

__author__ = 'BinglanLi'

import re
import pandas as pd
from pathlib import Path
from glob import glob

import utilities as util

if __name__ == "__main__":
    import argparse

    # describe the tool
    parser = argparse.ArgumentParser(description='Filter the PharmCAT autogenerated tests that failed in an expected '
                                                 'way.')

    # input arguments
    parser.add_argument("-f", "--failed-tests",
                        type=str,
                        required=False,
                        help="File containing the failed PharmCAT autogenerated tests.")

    parser.add_argument("-p", "--predicted-calls",
                        type=str,
                        required=False,
                        help="File containing the diplotype pairs predicted to be the same based on unphased "
                             "diplotype definitions.")

    # output args
    parser.add_argument("-o", "--output-dir",
                        type=str,
                        required=False,
                        metavar='<dir>',
                        help="(Optional) directory for outputs.  Defaults to the current working directory.")

    parser.add_argument("-bf", "--base-filename",
                        type=str,
                        required=False,
                        default='failed_tests',
                        help="(Optional) base filename of the output file.")

    # parse arguments
    args = parser.parse_args()
    # get the script directory path
    script_dir: Path = Path(globals().get("__file__", "./_")).absolute().parent

    # define output file name
    output_basename: str = args.base_filename
    # define output file path
    output_dir: Path = Path(args.output_dir) if args.output_dir else Path.cwd()
    if not args.output_dir:
        print(f'Output directory is not specified.\n'
              f'\tUse the current working directory: {output_dir}')

    # define the file path of reference predictions
    reference_file: Path
    if args.predicted_calls:
        reference_file = Path(args.predicted_calls).absolute()
    else:
        reference_file_dir: Path = Path(globals().get("__file__", "./_")).absolute().parent
        print(f'Looking for predicted_pharmcat_calls.tsv under the current working directory.')
        reference_file: Path = reference_file_dir / 'predicted_pharmcat_calls.tsv'
    # read reference predictions
    reference_predictions: pd.DataFrame = pd.read_csv(str(reference_file), delimiter='\t')
    # replace "NaN" values with ''
    reference_predictions = reference_predictions.fillna('')

    # define the autogenerated test report file path
    # this file is generated by the PharmCAT autogenerated tests
    test_file: Path
    if args.failed_tests:
        test_file = Path(args.failed_tests).absolute()
    else:
        print(f'Looking for autogenerated_test_report.tsv under the current working directory.')
        test_file: Path = script_dir / 'autogenerated_test_report.tsv'
    # read in test files
    autogenerated_tests: pd.DataFrame = pd.read_csv(str(test_file), delimiter='\t')
    # replace "NaN" values with ''
    autogenerated_tests = autogenerated_tests.fillna('')

    # define the allele definition json files
    json_dir: Path = script_dir.parent.parent / 'main/resources/org/pharmgkb/pharmcat/definition/alleles'
    allele_definition_jsons: list[str] = glob(str(json_dir.joinpath('*_translation.json')))
    # load alleles from pharmcat definition json files
    allele_definitions = dict()
    for json_file in allele_definition_jsons:
        # get the gene name
        gene: str = json_file.split('/')[-1].split('_')[0]
        # read the json file
        print(f'Processing {json_file}')
        json_data: dict = util.read_json(Path(json_file))

        # get allele list
        allele_list: list[str] = [entry['name'] for entry in json_data['namedAlleles']]

        # add to dictionary
        allele_definitions[gene] = allele_list

    # format the autogenerated test data frame - fix the expected diplotype
    failed_tests = pd.DataFrame(columns=autogenerated_tests.columns)
    for i in range(len(autogenerated_tests)):
        # identify the gene
        gene: str = autogenerated_tests.loc[i, 'Gene']
        # # skip G6PD for now
        # if gene == 'G6PD':
        #     print(f'\tSkipping for now...')
        #     continue

        # fix the Expected diplotype
        # get the list of diplotypes in a haplotype
        test_expected: str = autogenerated_tests.loc[i, 'Expected']
        # order alleles in a diplotype
        is_diplotype, test_expected_ordered = util.order_alleles_in_a_diplotype(test_expected, allele_definitions[gene])
        if not is_diplotype:
            print(f'\tFor a test on {test_expected}, more than two haplotypes were found based on \'/\' split. Skip...')
            continue

        # get the diplotype(s) in the Actual column
        test_actual: list[str] = autogenerated_tests.loc[i, 'Actual'].split(', ')
        test_actual_ordered = set()
        # order alleles in the Actual diplotype
        for x in test_actual:
            is_diplotype, x_ordered = util.order_alleles_in_a_diplotype(x, allele_definitions[gene])
            if is_diplotype:
                test_actual_ordered.add(x_ordered)
            else:
                print(f'\tFor a test on {test_expected}, more than two haplotypes were found in its actual call {x}. Skip...')
                continue

        # get the diplotype(s) in the Alt column
        test_alt_str: str = re.sub(r' \(\d+\)(, )?', ';', autogenerated_tests.loc[i, 'Alt'])
        test_alt_unordered: list[str] = test_alt_str.split(';')
        # order alleles in each diplotype
        test_alt_ordered = set()
        for x in test_alt_unordered:
            # skip if the alternative allele is an empty string
            if x == '':
                continue

            is_diplotype, x_ordered = util.order_alleles_in_a_diplotype(x, allele_definitions[gene])
            if is_diplotype:
                test_alt_ordered.add(x_ordered)
            else:
                print(f'\tFor a test on {test_expected}, more than two haplotypes were found in its alternative call {x}. Skip...')
                continue

        # get the list of missing positions
        test_missing_positions: set[str] = set(re.findall(r':(\d+)', autogenerated_tests.loc[i, 'Missing Positions']))

        # identify predictions for the Expected diplotype
        conditions = (reference_predictions['gene'] == gene) & \
                     (reference_predictions['expected'] == test_expected_ordered)
        matches = reference_predictions.loc[conditions].reset_index()

        # check whether alternative diplotypes match with the predictions
        n_matches: int = len(matches)
        # initiate a variable to determine whether the alternative calls match with any of the predictions
        has_matching_alt: bool = False
        # iterate over predictions
        for j in range(n_matches):
            # get the list of missing positions
            predicted_missing_positions: set[str] = set(re.findall(r'\.(\d+)', matches.loc[j, 'missing_positions']))
            # check on tested missing positions
            if test_missing_positions < predicted_missing_positions:
                continue

            # get the list of actual calls based on diplotype definitions
            predicted_actual: set[str] = set(matches.loc[j, 'actual'].split(';'))
            # get the list of alternative calls based on diplotype definitions
            predicted_alt: set[str] = set(matches.loc[j, 'alternative'].split(';'))
            # remove '' so that accidental '' introduced by splitting will not affect comparison
            if '' in predicted_alt:
                predicted_alt.remove('')

                # check whether the alternative calls are the same between the test and the prediction
            if test_actual_ordered == predicted_actual and test_alt_ordered == predicted_alt:
                has_matching_alt = True
                break
        # skip or add to failed tests
        if not has_matching_alt:
            failed_tests = pd.concat([failed_tests, autogenerated_tests.loc[i].to_frame().T], axis=0, ignore_index=True)

    # output failed tests
    output_file: Path = output_dir / (output_basename + '.tsv')
    failed_tests.to_csv(str(output_file), sep="\t", index=False)






